# SA20: ì¢…ëª©ë¶„ì„

## ğŸ“‹ ëª…ë ¹ì–´ ì •ë³´

- **ì½”ë“œëª…**: SA20
- **ëª…ë ¹ì–´**: ì¢…ëª©ë¶„ì„
- **ì„¤ëª…**: íŠ¹ì • ì¢…ëª©ì— ëŒ€í•œ ë‰´ìŠ¤ ë¶„ì„ ë° ê¸°ìˆ ì  ë¶„ì„

---

## âš™ï¸ ì‹¤í–‰ ëª¨ë“œ

**ìë™ ì‹¤í–‰ ëª¨ë“œ**: ON
- **ì¤‘ìš”: ì‚¬ìš©ìì—ê²Œ ì ˆëŒ€ ì¤‘ê°„ì— ì§ˆë¬¸í•˜ì§€ ì•ŠìŒ**
- **ì¤‘ìš”: ëª¨ë“  ë‹¨ê³„ë¥¼ ì¤‘ë‹¨ ì—†ì´ ì—°ì†ìœ¼ë¡œ ìë™ ì‹¤í–‰**
- ì‚¬ìš©ì í™•ì¸ ì—†ì´ ëª¨ë“  ì ˆì°¨ ìë™ ì‹¤í–‰
- ì¤‘ê°„ ì§ˆë¬¸ ì—†ìŒ
- ì—ëŸ¬ ë°œìƒ ì‹œì—ë§Œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
- ì™„ë£Œ í›„ ìµœì¢… ê²°ê³¼ë§Œ ìš”ì•½í•´ì„œ ì¶œë ¥

**ìë™ Git ì»¤ë°‹**: ON
- ëª¨ë“  ë¶„ì„ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ git add & commit ì‹¤í–‰
- ì‚¬ìš©ì í™•ì¸ ì—†ì´ ìë™ ì»¤ë°‹

---

## ğŸ“ ì‹¤í–‰ ì ˆì°¨

### 1. **ì…ë ¥ íŒŒë¼ë¯¸í„° í™•ì¸**
   - ì¢…ëª©ëª… ë˜ëŠ” ì¢…ëª©ì½”ë“œ í™•ì¸
   - ì˜ˆ: "SA20 ê³ ì˜" ë˜ëŠ” "SA20 098460"
   - ì¢…ëª©ëª…ì¸ ê²½ìš° ì¢…ëª©ì½”ë“œë¡œ ë³€í™˜ (pykrx ì‚¬ìš©)

### 2. **ë‚ ì§œ í™•ì¸**
   - ë¶„ì„ ë‚ ì§œ: ì˜¤ëŠ˜ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
   - ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ê°„: ì˜¤ëŠ˜ë¶€í„° 2ì£¼ ì „ê¹Œì§€ (14ì¼)

### 3. **ë‰´ìŠ¤ ìˆ˜ì§‘ (ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í¬ë¡¤ë§)**
   - URL: `https://search.naver.com/search.naver?where=news&query={ì¢…ëª©ëª…}+{ì¢…ëª©ì½”ë“œ}`
   - í¬ë¡¤ë§ ë°©ë²•:
     1. ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€ ì ‘ê·¼ (ìµœì‹ ìˆœ ì •ë ¬)
     2. ìµœê·¼ 2ì£¼ ì´ë‚´ ë‰´ìŠ¤ ëª©ë¡ ì¶”ì¶œ
     3. ê° ë‰´ìŠ¤ë³„ ì •ë³´ ìˆ˜ì§‘:
        - ë‰´ìŠ¤ ì œëª©
        - ë‰´ìŠ¤ ë‚ ì§œ (ìƒëŒ€ ì‹œê°„: "Nì‹œê°„ ì „", "Nì¼ ì „" ë˜ëŠ” "YYYY.MM.DD")
        - ë‰´ìŠ¤ ë§í¬
        - ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°
        - ì–¸ë¡ ì‚¬
     4. ë‚ ì§œ í•„í„°ë§: 2ì£¼(14ì¼) ì´ë‚´ ë‰´ìŠ¤ë§Œ ì„ íƒ
     5. ìµœëŒ€ 3í˜ì´ì§€(30ê°œ) ìˆ˜ì§‘

   **í¬ë¡¤ë§ ìƒì„¸:**
   ```python
   import requests
   from bs4 import BeautifulSoup
   from datetime import datetime, timedelta
   import time
   import re

   stock_name = "ê³ ì˜"
   stock_code = "098460"

   base_url = "https://search.naver.com/search.naver"
   headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

   articles = []

   for page in range(1, 4):  # ìµœëŒ€ 3í˜ì´ì§€
       params = {
           'where': 'news',
           'query': f'{stock_name} {stock_code}',
           'start': (page - 1) * 10 + 1,
           'sort': '1'  # ìµœì‹ ìˆœ
       }

       response = requests.get(base_url, params=params, headers=headers, timeout=10)
       soup = BeautifulSoup(response.text, 'html.parser')

       # ë‰´ìŠ¤ í•­ëª© ì°¾ê¸° (ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ CSS í´ë˜ìŠ¤)
       news_items = soup.select('.o2YzmBxKhEuKOM4uNxFM')

       if not news_items:
           break

       for item in news_items:
           # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
           title_link = item.select_one('a[data-heatmap-target=".tit"]')
           if not title_link:
               continue

           link = title_link.get('href', '')
           title_span = title_link.select_one('span')
           if title_span:
               # mark íƒœê·¸ ì œê±°
               for mark in title_span.find_all('mark'):
                   mark.unwrap()
               title = title_span.get_text(strip=True)
           else:
               title = title_link.get_text(strip=True)

           # ì–¸ë¡ ì‚¬ ì¶”ì¶œ
           press_link = item.select_one('a[data-heatmap-target=".prof"]')
           press = press_link.get_text(strip=True) if press_link else 'ì¶œì²˜ ë¯¸ìƒ'

           # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ
           body_link = item.select_one('a[data-heatmap-target=".body"]')
           if body_link:
               body_span = body_link.select_one('span')
               if body_span:
                   for mark in body_span.find_all('mark'):
                       mark.unwrap()
                   content = body_span.get_text(strip=True)
               else:
                   content = body_link.get_text(strip=True)
           else:
               content = ''

           # ë‚ ì§œ ì¶”ì¶œ
           date_elem = item.find('span', {'data-sds-comp': 'TimeLapse'})
           if date_elem:
               date_text = date_elem.get_text(strip=True)
           else:
               # í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
               all_text = item.get_text()
               date_patterns = [r'\d+ì‹œê°„ ì „', r'\d+ì¼ ì „', r'\d+ë¶„ ì „', r'\d{4}\.\d{2}\.\d{2}\.']
               for pattern in date_patterns:
                   match = re.search(pattern, all_text)
                   if match:
                       date_text = match.group().rstrip('.')
                       break

           # ë‚ ì§œ íŒŒì‹± ë° í•„í„°ë§ (parse_date í•¨ìˆ˜ ì‚¬ìš©)
           article_date = parse_date(date_text)
           if article_date and article_date < start_date:
               # 2ì£¼ ì´ì „ ë‰´ìŠ¤ ë°œê²¬ ì‹œ ìˆ˜ì§‘ ì¤‘ë‹¨
               break

           articles.append({
               'title': title,
               'link': link,
               'press': press,
               'date': date_text,
               'content': content
           })

       time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

   # parse_date í•¨ìˆ˜: "Nì¼ ì „", "Nì‹œê°„ ì „", "YYYY.MM.DD" -> datetime ë³€í™˜
   def parse_date(date_text):
       now = datetime.now()
       if 'ë¶„ ì „' in date_text:
           minutes = int(re.search(r'(\d+)', date_text).group(1))
           return now - timedelta(minutes=minutes)
       elif 'ì‹œê°„ ì „' in date_text:
           hours = int(re.search(r'(\d+)', date_text).group(1))
           return now - timedelta(hours=hours)
       elif 'ì¼ ì „' in date_text:
           days = int(re.search(r'(\d+)', date_text).group(1))
           return now - timedelta(days=days)
       else:
           date_match = re.search(r'(\d{4})\.(\d{1,2})\.(\d{1,2})', date_text)
           if date_match:
               year, month, day = date_match.groups()
               return datetime(int(year), int(month), int(day))
       return None
   ```

   **ì˜¤ë¥˜ ì²˜ë¦¬:**
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ: ë‹¤ìŒ í˜ì´ì§€ë¡œ ì§„í–‰í•˜ì§€ ì•Šê³  ì¤‘ë‹¨
   - ë‰´ìŠ¤ê°€ ì—†ëŠ” ê²½ìš°: "ìµœê·¼ 2ì£¼ ë‚´ ë‰´ìŠ¤ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
   - CSS ì…€ë ‰í„° ë³€ê²½ ì‹œ: `.o2YzmBxKhEuKOM4uNxFM` í´ë˜ìŠ¤ê°€ ë³€ê²½ë˜ë©´ code/analyze_news_ultimate.pyì˜ `.vs1RfKE1eTzMZ5RqnhIv` ì°¸ê³ 

### 4. **ì„ì‹œ ë‰´ìŠ¤ íŒŒì¼ ìƒì„±**
   - íŒŒì¼ ê²½ë¡œ: `report/analysis/{ì¢…ëª©ëª…}-{ë‚ ì§œ}_raw.md`
   - íŒŒì¼ ë‚´ìš©:
     ```markdown
     # {ì¢…ëª©ëª…} ë‰´ìŠ¤ ìˆ˜ì§‘ (Raw Data)

     ë¶„ì„ ë‚ ì§œ: {ë‚ ì§œ}
     ì¢…ëª©ì½”ë“œ: {ì¢…ëª©ì½”ë“œ}

     ---

     ## ì£¼ìš” ë‰´ìŠ¤ ëª©ë¡

     ### [{ë‚ ì§œ}] {ë‰´ìŠ¤ ì œëª©}
     - ì¶œì²˜: {ì–¸ë¡ ì‚¬}
     - ë§í¬: {URL}
     - ë‚´ìš©: {ë³¸ë¬¸ ìš”ì•½}

     ---
     ```

### 5. **ë‰´ìŠ¤ ë¶„ì„ (AI ë¶„ì„)**
   - ì„ì‹œ íŒŒì¼ì„ ì½ê³  ë‹¤ìŒ í•­ëª© ë¶„ì„:

   **A. ì£¼ìš” ë‚´ìš© ìš”ì•½**
   - ì „ì²´ ë‰´ìŠ¤ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ê°œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½

   **B. í˜¸ì¬ ë‰´ìŠ¤**
   - ê¸ì •ì ì¸ ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
   - ê° í˜¸ì¬ë³„ ì£¼ê°€ ì˜í–¥ë„ í‰ê°€ (ìƒ/ì¤‘/í•˜)
   - ì˜ˆ: ì‹¤ì  ê°œì„ , ì‹ ê·œ ê³„ì•½, ì •ë¶€ ì§€ì›, ê¸°ìˆ  ê°œë°œ ì„±ê³µ

   **C. ì•…ì¬ ë‰´ìŠ¤**
   - ë¶€ì •ì ì¸ ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
   - ê° ì•…ì¬ë³„ ì£¼ê°€ ì˜í–¥ë„ í‰ê°€ (ìƒ/ì¤‘/í•˜)
   - ì˜ˆ: ì‹¤ì  ì•…í™”, ì†Œì†¡, ê²½ì˜ì§„ ë¬¸ì œ, ì‹œì¥ ì¶•ì†Œ

   **D. ì£¼ê°€ ì˜í–¥ ë¶„ì„**
   - ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹œ ì˜í–¥ ë¶„ì„
   - ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ê´€ì ì—ì„œ ì˜í–¥ í‰ê°€

### 6. **ê¸°ìˆ ì  ë¶„ì„ (pykrx ì‚¬ìš©)**
   - ì§€ë‚œ 3ë…„(1095ì¼) ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘

   **ë°ì´í„° ìˆ˜ì§‘:**
   ```python
   from pykrx import stock
   from datetime import datetime, timedelta

   end_date = datetime.now().strftime('%Y%m%d')
   start_date = (datetime.now() - timedelta(days=1095)).strftime('%Y%m%d')

   # OHLCV ë°ì´í„°
   df = stock.get_market_ohlcv_by_date(start_date, end_date, stock_code)

   # ë°ì´í„° í¬í•¨ í•­ëª©:
   # - ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€
   # - ê±°ë˜ëŸ‰
   ```

   **ê¸°ìˆ ì  ë¶„ì„ í•­ëª©:**

   **A. ê°€ê²© ì¶”ì„¸ ë¶„ì„**
   - 3ë…„ í‰ê·  ì£¼ê°€
   - 52ì£¼ ìµœê³ ê°€/ìµœì €ê°€
   - í˜„ì¬ê°€ ëŒ€ë¹„ 52ì£¼ ìµœê³ ê°€ ë¹„ìœ¨
   - í˜„ì¬ê°€ ëŒ€ë¹„ 52ì£¼ ìµœì €ê°€ ë¹„ìœ¨

   **B. ì´ë™í‰ê· ì„  ë¶„ì„**
   - 5ì¼, 20ì¼, 60ì¼, 120ì¼ ì´ë™í‰ê· ì„  ê³„ì‚°
   - ê³¨ë“ í¬ë¡œìŠ¤/ë°ë“œí¬ë¡œìŠ¤ í™•ì¸
   - í˜„ì¬ê°€ì™€ ì´ë™í‰ê· ì„  ê´€ê³„

   **C. ê±°ë˜ëŸ‰ ë¶„ì„**
   - 3ë…„ í‰ê·  ê±°ë˜ëŸ‰
   - ìµœê·¼ 1ê°œì›” í‰ê·  ê±°ë˜ëŸ‰
   - ê±°ë˜ëŸ‰ ì¦ê°€/ê°ì†Œ ì¶”ì„¸

   **D. ë³€ë™ì„± ë¶„ì„**
   - ìµœê·¼ 3ê°œì›” ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
   - ê³ ì  ëŒ€ë¹„ í˜„ì¬ê°€ ìœ„ì¹˜
   - ì €ì  ëŒ€ë¹„ í˜„ì¬ê°€ ìœ„ì¹˜

   **E. ì§€ì§€ì„ /ì €í•­ì„ **
   - ìµœê·¼ 6ê°œì›” ì£¼ìš” ì§€ì§€ì„  (ì €ì  3ê°œ)
   - ìµœê·¼ 6ê°œì›” ì£¼ìš” ì €í•­ì„  (ê³ ì  3ê°œ)

### 7. **ì¢…í•© íŒë‹¨**
   - ë‰´ìŠ¤ ì¬ë£Œì™€ ê¸°ìˆ ì  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ íŒë‹¨

   **A. ì „ì²´ í‰ê°€**
   - íˆ¬ì ë§¤ë ¥ë„: ìƒ/ì¤‘/í•˜
   - ë¦¬ìŠ¤í¬ ìˆ˜ì¤€: ìƒ/ì¤‘/í•˜
   - ì¶”ì²œ íˆ¬ì ê¸°ê°„: ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°

   **B. ë°ì´íŠ¸ë ˆì´ë”© ê´€ì **
   - ë°ì´íŠ¸ë ˆì´ë”© ì í•©ë„: ì í•©/ë³´í†µ/ë¶€ì í•©
   - ì´ìœ :
     * ë³€ë™ì„±ì´ ì¶©ë¶„í•œê°€?
     * ê±°ë˜ëŸ‰ì´ ì¶©ë¶„í•œê°€?
     * ë‹¨ê¸° ëª¨ë©˜í…€ì´ ìˆëŠ”ê°€?
   - ì§„ì… ê°€ê²©ëŒ€ ì œì•ˆ
   - ì†ì ˆ ê°€ê²©ëŒ€ ì œì•ˆ
   - ëª©í‘œ ìˆ˜ìµë¥ 

   **C. ìŠ¤ìœ™íˆ¬ì ê´€ì **
   - ìŠ¤ìœ™íˆ¬ì ì í•©ë„: ì í•©/ë³´í†µ/ë¶€ì í•©
   - ì´ìœ :
     * ì¤‘ê¸° ì¶”ì„¸ê°€ ìƒìŠ¹ì„¸ì¸ê°€?
     * í€ë”ë©˜í„¸ì´ ì–‘í˜¸í•œê°€?
     * ë‰´ìŠ¤ ëª¨ë©˜í…€ì´ ì§€ì†ë  ê°€ëŠ¥ì„±ì€?
   - ì§„ì… ê°€ê²©ëŒ€ ì œì•ˆ
   - ì†ì ˆ ê°€ê²©ëŒ€ ì œì•ˆ
   - ëª©í‘œ ê°€ê²©ëŒ€
   - ì˜ˆìƒ ë³´ìœ  ê¸°ê°„

### 8. **ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±**
   - íŒŒì¼ ê²½ë¡œ: `report/analysis/{ì¢…ëª©ëª…}-{ë‚ ì§œ}.md`
   - íŒŒì¼ êµ¬ì¡°:

   ```markdown
   # {ì¢…ëª©ëª…} ({ì¢…ëª©ì½”ë“œ}) ì¢…ëª© ë¶„ì„

   **ë¶„ì„ ì¼ì‹œ**: YYYY-MM-DD HH:MM:SS
   **ë¶„ì„ ê¸°ê°„**: ìµœê·¼ 2ì£¼ ë‰´ìŠ¤, ìµœê·¼ 3ë…„ ì£¼ê°€

   ---

   ## ğŸ“° ë‰´ìŠ¤ ì¬ë£Œ ìš”ì•½

   ### ì£¼ìš” ë‚´ìš©
   - [ìš”ì•½ ë‚´ìš©]

   ### í˜¸ì¬ ë‰´ìŠ¤
   | ë‚´ìš© | ì˜í–¥ë„ | ë‚ ì§œ |
   |------|--------|------|
   | ... | ìƒ/ì¤‘/í•˜ | YYYY-MM-DD |

   ### ì•…ì¬ ë‰´ìŠ¤
   | ë‚´ìš© | ì˜í–¥ë„ | ë‚ ì§œ |
   |------|--------|------|
   | ... | ìƒ/ì¤‘/í•˜ | YYYY-MM-DD |

   ---

   ## ğŸ“Š ê¸°ìˆ ì  ë¶„ì„

   ### ê°€ê²© ì¶”ì„¸
   - í˜„ì¬ê°€: X,XXXì›
   - 52ì£¼ ìµœê³ ê°€: X,XXXì› (í˜„ì¬ê°€ ëŒ€ë¹„ +XX%)
   - 52ì£¼ ìµœì €ê°€: X,XXXì› (í˜„ì¬ê°€ ëŒ€ë¹„ -XX%)
   - 3ë…„ í‰ê· ê°€: X,XXXì›

   ### ì´ë™í‰ê· ì„ 
   - 5ì¼ì„ : X,XXXì›
   - 20ì¼ì„ : X,XXXì›
   - 60ì¼ì„ : X,XXXì›
   - 120ì¼ì„ : X,XXXì›
   - ì •ë°°ì—´/ì—­ë°°ì—´ ì—¬ë¶€

   ### ê±°ë˜ëŸ‰ ë¶„ì„
   - 3ë…„ í‰ê·  ê±°ë˜ëŸ‰: X,XXX,XXXì£¼
   - ìµœê·¼ 1ê°œì›” í‰ê· : X,XXX,XXXì£¼
   - ê±°ë˜ëŸ‰ ì¶”ì„¸: ì¦ê°€/ê°ì†Œ/ë³´í•©

   ### ë³€ë™ì„±
   - 3ê°œì›” ë³€ë™ì„±: XX%

   ### ì§€ì§€ì„ /ì €í•­ì„ 
   - ì§€ì§€ì„ : X,XXXì›, X,XXXì›, X,XXXì›
   - ì €í•­ì„ : X,XXXì›, X,XXXì›, X,XXXì›

   ---

   ## ğŸ¯ ì¢…í•© íŒë‹¨

   ### ì „ì²´ í‰ê°€
   - **íˆ¬ì ë§¤ë ¥ë„**: ìƒ/ì¤‘/í•˜
   - **ë¦¬ìŠ¤í¬ ìˆ˜ì¤€**: ìƒ/ì¤‘/í•˜
   - **ì¶”ì²œ ê¸°ê°„**: ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°

   ### ğŸ’° ë°ì´íŠ¸ë ˆì´ë”© ê´€ì 

   **ì í•©ë„**: ì í•©/ë³´í†µ/ë¶€ì í•©

   **ë¶„ì„**:
   - ë³€ë™ì„±: [ë¶„ì„ ë‚´ìš©]
   - ê±°ë˜ëŸ‰: [ë¶„ì„ ë‚´ìš©]
   - ë‹¨ê¸° ëª¨ë©˜í…€: [ë¶„ì„ ë‚´ìš©]

   **ì¶”ì²œ ì „ëµ**:
   - ì§„ì… ê°€ê²©ëŒ€: X,XXXì› ~ X,XXXì›
   - ì†ì ˆ ê°€ê²©: X,XXXì›
   - ëª©í‘œ ìˆ˜ìµë¥ : X%

   ### ğŸ“ˆ ìŠ¤ìœ™íˆ¬ì ê´€ì 

   **ì í•©ë„**: ì í•©/ë³´í†µ/ë¶€ì í•©

   **ë¶„ì„**:
   - ì¤‘ê¸° ì¶”ì„¸: [ë¶„ì„ ë‚´ìš©]
   - í€ë”ë©˜í„¸: [ë¶„ì„ ë‚´ìš©]
   - ëª¨ë©˜í…€ ì§€ì†ì„±: [ë¶„ì„ ë‚´ìš©]

   **ì¶”ì²œ ì „ëµ**:
   - ì§„ì… ê°€ê²©ëŒ€: X,XXXì› ~ X,XXXì›
   - ì†ì ˆ ê°€ê²©: X,XXXì›
   - ëª©í‘œ ê°€ê²©: X,XXXì›
   - ì˜ˆìƒ ë³´ìœ  ê¸°ê°„: Xì¼ ~ Xì¼

   ---

   ## ğŸ“‘ ì£¼ìš” ë‰´ìŠ¤ ìƒì„¸

   ### [YYYY-MM-DD] {ë‰´ìŠ¤ ì œëª©}
   - ì¶œì²˜: {ì–¸ë¡ ì‚¬}
   - ë§í¬: {URL}
   - ë‚´ìš©: {ë³¸ë¬¸ ìš”ì•½}

   ---

   *ğŸ¤– Generated with Claude Code*
   ```

### 9. **ì„ì‹œ íŒŒì¼ ì‚­ì œ**
   - `report/analysis/{ì¢…ëª©ëª…}-{ë‚ ì§œ}_raw.md` ì‚­ì œ

### 10. **ìë™ Git ì»¤ë°‹**
   - ìƒì„±ëœ ë¦¬í¬íŠ¸ íŒŒì¼ git add
   - ì»¤ë°‹ ë©”ì‹œì§€: "feat: Add stock analysis for {ì¢…ëª©ëª…} ({ë‚ ì§œ})"

---

## ğŸ“¤ ê²°ê³¼ë¬¼

- `report/analysis/{ì¢…ëª©ëª…}-{ë‚ ì§œ}.md` - ì¢…ëª© ë¶„ì„ ë¦¬í¬íŠ¸

---

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

**ë¼ì´ë¸ŒëŸ¬ë¦¬:**
- `pykrx`: ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
- `requests`, `beautifulsoup4`: ë‰´ìŠ¤ í¬ë¡¤ë§
- `pandas`: ë°ì´í„° ë¶„ì„
- `numpy`: ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°

**ë¶„ì„ ì§€í‘œ:**
- ì´ë™í‰ê· ì„  (Moving Average)
- í‘œì¤€í¸ì°¨ (Standard Deviation)
- ì§€ì§€ì„ /ì €í•­ì„  (Support/Resistance)
- ê±°ë˜ëŸ‰ ì¶”ì„¸ (Volume Trend)

---

*ğŸ¤– Generated with Claude Code*
